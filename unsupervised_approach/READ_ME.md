## Unsupervised approaches


### notebooks 

 - *Inception_transfer_values.ipynb*: transfer learning; uses last layer of pretrained CNN Inception v3 as vector for clustering. 

Result: clustering not good; 

What to improve: clustering approach; fine tune model before extracting the last layer;

 - *Train_variational_autoencoder.ipynb*: simplest form of AE; 

Result: decoding very blurry

What to improve: training time? but will always be blurry

 - *Train_deep_autoencoder.ipynb*: advanced form of AE

Result: models are very big (GB)!! limited by number of params, 400 million!

What to improve: 

 - *Train_convolutional_autoencoder.ipynb*: best AE;

Result: models are small; decoding image quality very good; clustering not good enough 

What to improve: clustering approach; reduce latent vector dimensions without loosing decoded image quality;

**ConvAE_v4** was best trained model

 - *encode_images.ipynb*: uses encoder model to encode images to latent vectors, and saves them as numpy array 
 - *Save_encod_decod_images.ipynb*: generates png files of latent vectors (encoded) and decoded images for figures
 - *Cluster_latent_vectors.ipynb*: applies dimensionality reduction to latent vectors, clusters, compares to ground truth labels


### results_ConvAE_v4 

contains files from the best trained convolutional autoencoder, in particular:

 - the encoder model (Conv_AE_v4_encoder.h5)
 - the complete encoder and decoder model (Conv_AE_v4.h5)
 - the loss curve from training 50 epoches (Loss_curve_Conv_AE_v4.pdf)
 - a list of image names used to test the model (Image_names_Conv_AE_v4.csv)
 - the latent vectors of the test images (Latent_vectors_Conv_AE_v4.npy)
 - the true labels of the test images, generated by Simon (Image_labels.csv)





